{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dsahoo17/GestureRecognition/blob/master/Flair_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9ftlbgfM-U6"
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus, ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings,DocumentLSTMEmbeddings, BertEmbeddings, StackedEmbeddings, TokenEmbeddings\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "from typing import List\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IP5paEQ5N3By",
    "outputId": "4ef38a16-4833-4f68-bfa9-cb2969d9dc4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show O\n",
      "me O\n",
      "the O\n",
      "flights O\n",
      "to O\n",
      "love I-location_detail\n",
      "field I-location_detail\n",
      "\n",
      "show O\n",
      "me O\n",
      "all O\n",
      "flights O\n",
      "from O\n",
      "boston I-location_detail\n",
      "to O\n",
      "denver I-location_detail\n",
      "\n",
      "philadelphia I-location_detail\n",
      "to O\n",
      "san I-location_detail\n",
      "francisco I-location_detail\n",
      "monday I-depart\n",
      "\n",
      "from O\n",
      "san O\n",
      "francisco O\n",
      "on O\n",
      "tuesday I-depart\n",
      "\n",
      "show O\n",
      "me O\n",
      "all O\n",
      "flights O\n",
      "from O\n",
      "san I-location_detail\n",
      "francisco I-location_detail\n",
      "to O\n",
      "washington I-location_detail\n",
      "dc I-location_detail\n",
      "area O\n",
      "\n",
      "sure O\n",
      "i O\n",
      "want O\n",
      "to O\n",
      "go O\n",
      "from O\n",
      "philadelphia I-location_detail\n",
      "to O\n",
      "dallas I-location_detail\n",
      "\n",
      "show O\n",
      "me O\n",
      "all O\n",
      "the O\n",
      "available O\n",
      "flights O\n",
      "from O\n",
      "baltimore I-location_detail\n",
      "to O\n",
      "dallas I-location_detail\n",
      "with O\n",
      "economy I-aircraft_detail\n",
      "fares O\n",
      "\n",
      "show O\n",
      "me O\n",
      "the O\n",
      "flights O\n",
      "from O\n",
      "philadelphia I-location_detail\n",
      "to O\n",
      "atlanta I-location_detail\n",
      "\n",
      "show O\n",
      "me O\n",
      "the O\n",
      "latest I-flight_detail\n",
      "dinner I-aircraft_detail\n",
      "flight O\n",
      "from O\n",
      "baltimore I-location_detail\n",
      "to O\n",
      "oakland I-location_detail\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('flair/train.txt', 'r') as train_txt: \n",
    "    print(train_txt.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-18 16:57:25,312 Reading data from flair\n",
      "2020-07-18 16:57:25,315 Train: flair/train.txt\n",
      "2020-07-18 16:57:25,318 Dev: None\n",
      "2020-07-18 16:57:25,319 Test: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_folder = \"./flair\"\n",
    "model_dir = \"./\"\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                                      train_file='train.txt',\n",
    "                                      #test_file='test.txt',\n",
    "                                      # dev_file='dev.txt'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gqTIylgW4l5"
   },
   "outputs": [],
   "source": [
    "tag_type = 'ner'\n",
    "\n",
    "#on utilise la deuxième colonne ici correspondant aux labels pour la ner\n",
    "\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "#on récupère la liste des labels\n",
    "\n",
    "\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "            WordEmbeddings('fr'),\n",
    "            FlairEmbeddings('fr-forward'),\n",
    "            FlairEmbeddings('fr-backward'),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permet de combiner les embeddings\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                                embeddings=embeddings,\n",
    "                                                tag_dictionary=tag_dictionary,\n",
    "                                                tag_type=tag_type,\n",
    "                                                use_crf=True)\n",
    "#regarder tous les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vj73Ih39V7UQ",
    "outputId": "5b8f5727-c1dc-4a94-b0de-441872f9968e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-18 16:57:37,461 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:37,463 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('fr')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (encoder): Embedding(275, 100)\n",
      "        (rnn): LSTM(100, 1024)\n",
      "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (encoder): Embedding(275, 100)\n",
      "        (rnn): LSTM(100, 1024)\n",
      "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2348, out_features=2348, bias=True)\n",
      "  (rnn): LSTM(2348, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-07-18 16:57:37,464 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:37,465 Corpus: \"Corpus: 7 train + 1 dev + 1 test sentences\"\n",
      "2020-07-18 16:57:37,466 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:37,467 Parameters:\n",
      "2020-07-18 16:57:37,468  - learning_rate: \"0.1\"\n",
      "2020-07-18 16:57:37,469  - mini_batch_size: \"32\"\n",
      "2020-07-18 16:57:37,470  - patience: \"3\"\n",
      "2020-07-18 16:57:37,471  - anneal_factor: \"0.5\"\n",
      "2020-07-18 16:57:37,472  - max_epochs: \"10\"\n",
      "2020-07-18 16:57:37,473  - shuffle: \"True\"\n",
      "2020-07-18 16:57:37,474  - train_with_dev: \"False\"\n",
      "2020-07-18 16:57:37,475  - batch_growth_annealing: \"False\"\n",
      "2020-07-18 16:57:37,475 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:37,476 Model training base path: \".\"\n",
      "2020-07-18 16:57:37,477 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:37,478 Device: cpu\n",
      "2020-07-18 16:57:37,479 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:37,480 Embeddings storage mode: cpu\n",
      "2020-07-18 16:57:37,484 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:38,389 epoch 1 - iter 1/1 - loss 22.22522545 - samples/sec: 35.60\n",
      "2020-07-18 16:57:39,960 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:57:39,961 EPOCH 1 done: loss 22.2252 - lr 0.1000000\n",
      "2020-07-18 16:57:40,088 DEV : loss 18.136981964111328 - score 0.375\n",
      "2020-07-18 16:57:40,089 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 16:58:26,994 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:58:27,378 epoch 2 - iter 1/1 - loss 17.39396477 - samples/sec: 85.22\n",
      "2020-07-18 16:58:28,821 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:58:28,822 EPOCH 2 done: loss 17.3940 - lr 0.1000000\n",
      "2020-07-18 16:58:28,848 DEV : loss 12.955446243286133 - score 0.75\n",
      "2020-07-18 16:58:28,849 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 16:59:07,380 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:59:07,514 epoch 3 - iter 1/1 - loss 13.37703514 - samples/sec: 240.92\n",
      "2020-07-18 16:59:09,100 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:59:09,101 EPOCH 3 done: loss 13.3770 - lr 0.1000000\n",
      "2020-07-18 16:59:09,117 DEV : loss 9.529614448547363 - score 0.75\n",
      "2020-07-18 16:59:09,122 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 16:59:44,364 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:59:44,587 epoch 4 - iter 1/1 - loss 10.91044521 - samples/sec: 144.98\n",
      "2020-07-18 16:59:46,135 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 16:59:46,136 EPOCH 4 done: loss 10.9104 - lr 0.1000000\n",
      "2020-07-18 16:59:46,156 DEV : loss 8.161673545837402 - score 0.75\n",
      "2020-07-18 16:59:46,158 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 17:00:22,691 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:00:22,821 epoch 5 - iter 1/1 - loss 9.62004089 - samples/sec: 247.60\n",
      "2020-07-18 17:00:24,270 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:00:24,271 EPOCH 5 done: loss 9.6200 - lr 0.1000000\n",
      "2020-07-18 17:00:24,291 DEV : loss 8.15420150756836 - score 0.75\n",
      "2020-07-18 17:00:24,293 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 17:00:59,582 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:00:59,678 epoch 6 - iter 1/1 - loss 10.57906437 - samples/sec: 339.04\n",
      "2020-07-18 17:01:01,112 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:01:01,113 EPOCH 6 done: loss 10.5791 - lr 0.1000000\n",
      "2020-07-18 17:01:01,139 DEV : loss 7.175506591796875 - score 0.875\n",
      "2020-07-18 17:01:01,140 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 17:01:35,749 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:01:35,857 epoch 7 - iter 1/1 - loss 8.50688076 - samples/sec: 301.00\n",
      "2020-07-18 17:01:37,310 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:01:37,311 EPOCH 7 done: loss 8.5069 - lr 0.1000000\n",
      "2020-07-18 17:01:37,330 DEV : loss 7.243679046630859 - score 0.75\n",
      "2020-07-18 17:01:37,331 BAD EPOCHS (no improvement): 1\n",
      "2020-07-18 17:01:37,342 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:01:37,467 epoch 8 - iter 1/1 - loss 9.52314568 - samples/sec: 259.07\n",
      "2020-07-18 17:01:38,895 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:01:38,896 EPOCH 8 done: loss 9.5231 - lr 0.1000000\n",
      "2020-07-18 17:01:38,920 DEV : loss 6.209869384765625 - score 0.875\n",
      "2020-07-18 17:01:38,922 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 17:02:14,251 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:02:14,369 epoch 9 - iter 1/1 - loss 8.13816071 - samples/sec: 274.16\n",
      "2020-07-18 17:02:15,820 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:02:15,821 EPOCH 9 done: loss 8.1382 - lr 0.1000000\n",
      "2020-07-18 17:02:15,839 DEV : loss 6.533681869506836 - score 0.75\n",
      "2020-07-18 17:02:15,840 BAD EPOCHS (no improvement): 1\n",
      "2020-07-18 17:02:15,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:02:15,956 epoch 10 - iter 1/1 - loss 9.15149593 - samples/sec: 298.19\n",
      "2020-07-18 17:02:17,411 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:02:17,412 EPOCH 10 done: loss 9.1515 - lr 0.1000000\n",
      "2020-07-18 17:02:17,430 DEV : loss 5.199947357177734 - score 0.875\n",
      "2020-07-18 17:02:17,432 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-18 17:03:33,241 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-18 17:03:33,249 Testing using best model ...\n",
      "2020-07-18 17:03:33,267 loading file best-model.pt\n",
      "2020-07-18 17:04:20,536 \t0.8182\n",
      "2020-07-18 17:04:20,544 \n",
      "Results:\n",
      "- F-score (micro) 0.8182\n",
      "- F-score (macro) 0.8167\n",
      "- Accuracy 0.8182\n",
      "\n",
      "By class:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                O     1.0000    0.7143    0.8333         7\n",
      "I-location_detail     0.6667    1.0000    0.8000         4\n",
      "\n",
      "         accuracy                         0.8182        11\n",
      "        macro avg     0.8333    0.8571    0.8167        11\n",
      "     weighted avg     0.8788    0.8182    0.8212        11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-18 17:04:20,545 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8182,\n",
       " 'dev_score_history': [0.375,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.875,\n",
       "  0.75,\n",
       "  0.875,\n",
       "  0.75,\n",
       "  0.875],\n",
       " 'train_loss_history': [22.2252254486084,\n",
       "  17.393964767456055,\n",
       "  13.377035140991211,\n",
       "  10.910445213317871,\n",
       "  9.620040893554688,\n",
       "  10.57906436920166,\n",
       "  8.506880760192871,\n",
       "  9.52314567565918,\n",
       "  8.138160705566406,\n",
       "  9.151495933532715],\n",
       " 'dev_loss_history': [18.136981964111328,\n",
       "  12.955446243286133,\n",
       "  9.529614448547363,\n",
       "  8.161673545837402,\n",
       "  8.15420150756836,\n",
       "  7.175506591796875,\n",
       "  7.243679046630859,\n",
       "  6.209869384765625,\n",
       "  6.533681869506836,\n",
       "  5.199947357177734]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On crée un objet pour train avec flair. Ici on utilise seulement des données de train\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "#On lance le training\n",
    "trainer.train(model_dir,learning_rate=0.1,mini_batch_size=32, max_epochs=10,embeddings_storage_mode='cpu',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4A6DGl1zW3IQ",
    "outputId": "bb8ba455-7d0d-47bf-d348-0aa940b60355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-18 17:04:20,619 loading file ./best-model.pt\n"
     ]
    }
   ],
   "source": [
    "#On récupère le meilleur modèle, stocké sous ce nom par Flair\n",
    "model = SequenceTagger.load('./best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-18 17:06:39,675 Reading data from flair\n",
      "2020-07-18 17:06:39,676 Train: flair/train.txt\n",
      "2020-07-18 17:06:39,677 Dev: None\n",
      "2020-07-18 17:06:39,678 Test: flair/test.txt\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"./flair\"\n",
    "\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "corpus2: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                                    train_file=None,\n",
    "                                      test_file='test.txt',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, eval_loss = model.evaluate(corpus2.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "- F-score (micro) 0.5556\n",
      "- F-score (macro) 0.4444\n",
      "- Accuracy 0.5556\n",
      "\n",
      "By class:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "I-location_detail     1.0000    0.5000    0.6667         2\n",
      "                O     0.5000    1.0000    0.6667         4\n",
      "         I-arrive     1.0000    0.0000    0.0000         3\n",
      "\n",
      "         accuracy                         0.5556         9\n",
      "        macro avg     0.8333    0.5000    0.4444         9\n",
      "     weighted avg     0.7778    0.5556    0.4444         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.detailed_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philadelphia <I-location_detail> to dallas <I-location_detail> arriving before <I-arrive> 1 <I-arrive> in the afternoon <I-arrive>\n"
     ]
    }
   ],
   "source": [
    "print(corpus2.test[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philadelphia to dallas arriving before 1 in the afternoon\n",
      "philadelphia <I-location_detail> to dallas arriving before 1 in the afternoon\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = corpus2.test[0]\n",
    "sentence =test.to_plain_string()\n",
    "print(sentence)\n",
    "tests = Sentence(sentence)\n",
    "model.predict(tests)\n",
    "print(tests.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMt/t0JxwEffzpT7O9gS5yT",
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

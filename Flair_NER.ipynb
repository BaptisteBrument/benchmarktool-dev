{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dsahoo17/GestureRecognition/blob/master/Flair_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9ftlbgfM-U6"
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus, ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings,DocumentLSTMEmbeddings, BertEmbeddings, StackedEmbeddings, TokenEmbeddings\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "from typing import List\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IP5paEQ5N3By",
    "outputId": "4ef38a16-4833-4f68-bfa9-cb2969d9dc4b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show O\n",
      "me O\n",
      "the O\n",
      "flights O\n",
      "to O\n",
      "love I-location_detail\n",
      "field I-location_detail\n",
      "\n",
      "show O\n",
      "me O\n",
      "all O\n",
      "flights O\n",
      "from O\n",
      "boston I-location_detail\n",
      "to O\n",
      "denver I-location_detail\n",
      "\n",
      "philadelphia I-location_detail\n",
      "to O\n",
      "san I-location_detail\n",
      "francisco I-location_detail\n",
      "monday I-depart\n",
      "\n",
      "from O\n",
      "san O\n",
      "francisco O\n",
      "on O\n",
      "tuesday I-depart\n",
      "\n",
      "show O\n",
      "me O\n",
      "all O\n",
      "flights O\n",
      "from O\n",
      "san I-location_detail\n",
      "francisco I-location_detail\n",
      "to O\n",
      "washington I-location_detail\n",
      "dc I-location_detail\n",
      "area O\n",
      "\n",
      "sure O\n",
      "i O\n",
      "want O\n",
      "to O\n",
      "go O\n",
      "from O\n",
      "philadelphia I-location_detail\n",
      "to O\n",
      "dallas I-location_detail\n",
      "\n",
      "show O\n",
      "me O\n",
      "all O\n",
      "the O\n",
      "available O\n",
      "flights O\n",
      "from O\n",
      "baltimore I-location_detail\n",
      "to O\n",
      "dallas I-location_detail\n",
      "with O\n",
      "economy I-aircraft_detail\n",
      "fares O\n",
      "\n",
      "show O\n",
      "me O\n",
      "the O\n",
      "flights O\n",
      "from O\n",
      "philadelphia I-location_detail\n",
      "to O\n",
      "atlanta I-location_detail\n",
      "\n",
      "show O\n",
      "me O\n",
      "the O\n",
      "latest I-flight_detail\n",
      "dinner I-aircraft_detail\n",
      "flight O\n",
      "from O\n",
      "baltimore I-location_detail\n",
      "to O\n",
      "oakland I-location_detail\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('flair/train.txt', 'r') as train_txt: \n",
    "    print(train_txt.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= \"show O\\n me O\\nthe O\\nflights O\\nto O\\nlove I-location_detail\\nfield I-location_detail\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-12 10:06:43,202 Reading data from flair\n",
      "2020-08-12 10:06:43,204 Train: flair/show O\n",
      " me O\n",
      "the O\n",
      "flights O\n",
      "to O\n",
      "love I-location_detail\n",
      "field I-location_detail\n",
      "2020-08-12 10:06:43,205 Dev: None\n",
      "2020-08-12 10:06:43,207 Test: None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0d888b182d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ner'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m corpus: Corpus = ColumnCorpus(data_folder, columns,\n\u001b[0;32m----> 5\u001b[0;31m                                       \u001b[0mtrain_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                                       \u001b[0;31m#test_file='test.txt',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                       \u001b[0;31m# dev_file='dev.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/flair/datasets/sequence_labeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_folder, column_format, train_file, test_file, dev_file, tag_to_bioes, column_delimiter, comment_symbol, encoding, document_separator_token, skip_first_line, in_memory)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mdocument_separator_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocument_separator_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mskip_first_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_first_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/flair/datasets/sequence_labeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_to_column_file, column_name_map, tag_to_bioes, column_delimiter, comment_symbol, in_memory, document_separator_token, encoding, skip_first_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_column_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mpath_to_column_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_column_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mpath_to_column_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_column_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_column_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_to_bioes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_to_bioes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "data_folder = \"./flair\"\n",
    "model_dir = \"./\"\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                                      train_file=test,\n",
    "                                      #test_file='test.txt',\n",
    "                                      # dev_file='dev.txt'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gqTIylgW4l5"
   },
   "outputs": [],
   "source": [
    "tag_type = 'ner'\n",
    "\n",
    "#on utilise la deuxième colonne ici correspondant aux labels pour la ner\n",
    "\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "#on récupère la liste des labels\n",
    "\n",
    "\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "            WordEmbeddings('fr'),\n",
    "            FlairEmbeddings('fr-forward'),\n",
    "            FlairEmbeddings('fr-backward'),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permet de combiner les embeddings\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                                embeddings=embeddings,\n",
    "                                                tag_dictionary=tag_dictionary,\n",
    "                                                tag_type=tag_type,\n",
    "                                                use_crf=True)\n",
    "#regarder tous les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vj73Ih39V7UQ",
    "outputId": "5b8f5727-c1dc-4a94-b0de-441872f9968e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 09:59:02,553 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:02,554 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('fr')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (encoder): Embedding(275, 100)\n",
      "        (rnn): LSTM(100, 1024)\n",
      "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (encoder): Embedding(275, 100)\n",
      "        (rnn): LSTM(100, 1024)\n",
      "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2348, out_features=2348, bias=True)\n",
      "  (rnn): LSTM(2348, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-07-24 09:59:02,556 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:02,557 Corpus: \"Corpus: 7 train + 1 dev + 1 test sentences\"\n",
      "2020-07-24 09:59:02,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:02,558 Parameters:\n",
      "2020-07-24 09:59:02,559  - learning_rate: \"0.1\"\n",
      "2020-07-24 09:59:02,560  - mini_batch_size: \"32\"\n",
      "2020-07-24 09:59:02,561  - patience: \"3\"\n",
      "2020-07-24 09:59:02,562  - anneal_factor: \"0.5\"\n",
      "2020-07-24 09:59:02,563  - max_epochs: \"10\"\n",
      "2020-07-24 09:59:02,565  - shuffle: \"True\"\n",
      "2020-07-24 09:59:02,566  - train_with_dev: \"False\"\n",
      "2020-07-24 09:59:02,566  - batch_growth_annealing: \"False\"\n",
      "2020-07-24 09:59:02,567 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:02,568 Model training base path: \".\"\n",
      "2020-07-24 09:59:02,568 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:02,570 Device: cpu\n",
      "2020-07-24 09:59:02,570 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:02,571 Embeddings storage mode: cpu\n",
      "2020-07-24 09:59:02,574 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:03,242 epoch 1 - iter 1/1 - loss 27.51511955 - samples/sec: 48.33\n",
      "2020-07-24 09:59:04,626 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:04,627 EPOCH 1 done: loss 27.5151 - lr 0.1000000\n",
      "2020-07-24 09:59:04,715 DEV : loss 9.193687438964844 - score 0.2\n",
      "2020-07-24 09:59:04,716 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-24 09:59:41,672 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:41,821 epoch 2 - iter 1/1 - loss 20.71101570 - samples/sec: 219.72\n",
      "2020-07-24 09:59:43,184 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 09:59:43,185 EPOCH 2 done: loss 20.7110 - lr 0.1000000\n",
      "2020-07-24 09:59:43,203 DEV : loss 6.049406051635742 - score 0.4\n",
      "2020-07-24 09:59:43,205 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-24 10:00:19,184 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:00:19,300 epoch 3 - iter 1/1 - loss 13.66797447 - samples/sec: 278.03\n",
      "2020-07-24 10:00:20,664 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:00:20,664 EPOCH 3 done: loss 13.6680 - lr 0.1000000\n",
      "2020-07-24 10:00:20,681 DEV : loss 3.805983543395996 - score 0.8\n",
      "2020-07-24 10:00:20,682 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-24 10:00:57,714 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:00:57,868 epoch 4 - iter 1/1 - loss 9.42938900 - samples/sec: 210.46\n",
      "2020-07-24 10:00:59,328 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:00:59,329 EPOCH 4 done: loss 9.4294 - lr 0.1000000\n",
      "2020-07-24 10:00:59,345 DEV : loss 5.16436767578125 - score 0.4\n",
      "2020-07-24 10:00:59,347 BAD EPOCHS (no improvement): 1\n",
      "2020-07-24 10:00:59,358 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:00:59,464 epoch 5 - iter 1/1 - loss 7.38790751 - samples/sec: 304.37\n",
      "2020-07-24 10:01:00,953 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:00,954 EPOCH 5 done: loss 7.3879 - lr 0.1000000\n",
      "2020-07-24 10:01:00,973 DEV : loss 3.4599838256835938 - score 0.8\n",
      "2020-07-24 10:01:00,979 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-07-24 10:01:38,207 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:38,304 epoch 6 - iter 1/1 - loss 8.60444927 - samples/sec: 335.86\n",
      "2020-07-24 10:01:39,679 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:39,680 EPOCH 6 done: loss 8.6044 - lr 0.1000000\n",
      "2020-07-24 10:01:39,695 DEV : loss 5.8939008712768555 - score 0.4\n",
      "2020-07-24 10:01:39,696 BAD EPOCHS (no improvement): 1\n",
      "2020-07-24 10:01:39,704 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:39,815 epoch 7 - iter 1/1 - loss 7.12998056 - samples/sec: 291.98\n",
      "2020-07-24 10:01:41,195 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:41,196 EPOCH 7 done: loss 7.1300 - lr 0.1000000\n",
      "2020-07-24 10:01:41,211 DEV : loss 3.7398252487182617 - score 0.8\n",
      "2020-07-24 10:01:41,212 BAD EPOCHS (no improvement): 2\n",
      "2020-07-24 10:01:41,219 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:41,354 epoch 8 - iter 1/1 - loss 8.27322578 - samples/sec: 240.20\n",
      "2020-07-24 10:01:42,731 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:42,732 EPOCH 8 done: loss 8.2732 - lr 0.1000000\n",
      "2020-07-24 10:01:42,748 DEV : loss 6.817975044250488 - score 0.2\n",
      "2020-07-24 10:01:42,749 BAD EPOCHS (no improvement): 3\n",
      "2020-07-24 10:01:42,757 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:42,855 epoch 9 - iter 1/1 - loss 6.87079096 - samples/sec: 329.77\n",
      "2020-07-24 10:01:44,213 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:44,215 EPOCH 9 done: loss 6.8708 - lr 0.1000000\n",
      "2020-07-24 10:01:44,229 DEV : loss 3.764881134033203 - score 0.8\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-07-24 10:01:44,231 BAD EPOCHS (no improvement): 4\n",
      "2020-07-24 10:01:44,246 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:44,344 epoch 10 - iter 1/1 - loss 7.38992405 - samples/sec: 332.59\n",
      "2020-07-24 10:01:45,705 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:01:45,707 EPOCH 10 done: loss 7.3899 - lr 0.0500000\n",
      "2020-07-24 10:01:45,722 DEV : loss 4.870856285095215 - score 0.6\n",
      "2020-07-24 10:01:45,723 BAD EPOCHS (no improvement): 1\n",
      "2020-07-24 10:02:20,812 ----------------------------------------------------------------------------------------------------\n",
      "2020-07-24 10:02:20,813 Testing using best model ...\n",
      "2020-07-24 10:02:20,815 loading file best-model.pt\n",
      "2020-07-24 10:02:55,926 \t0.2\n",
      "2020-07-24 10:02:55,930 \n",
      "Results:\n",
      "- F-score (micro) 0.2\n",
      "- F-score (macro) 0.1111\n",
      "- Accuracy 0.2\n",
      "\n",
      "By class:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "I-location_detail     1.0000    0.0000    0.0000         3\n",
      "                O     0.2000    1.0000    0.3333         1\n",
      "         I-depart     1.0000    0.0000    0.0000         1\n",
      "\n",
      "         accuracy                         0.2000         5\n",
      "        macro avg     0.7333    0.3333    0.1111         5\n",
      "     weighted avg     0.8400    0.2000    0.0667         5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 10:02:55,931 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.2,\n",
       " 'dev_score_history': [0.2, 0.4, 0.8, 0.4, 0.8, 0.4, 0.8, 0.2, 0.8, 0.6],\n",
       " 'train_loss_history': [27.515119552612305,\n",
       "  20.711015701293945,\n",
       "  13.667974472045898,\n",
       "  9.429388999938965,\n",
       "  7.3879075050354,\n",
       "  8.604449272155762,\n",
       "  7.129980564117432,\n",
       "  8.273225784301758,\n",
       "  6.870790958404541,\n",
       "  7.389924049377441],\n",
       " 'dev_loss_history': [9.193687438964844,\n",
       "  6.049406051635742,\n",
       "  3.805983543395996,\n",
       "  5.16436767578125,\n",
       "  3.4599838256835938,\n",
       "  5.8939008712768555,\n",
       "  3.7398252487182617,\n",
       "  6.817975044250488,\n",
       "  3.764881134033203,\n",
       "  4.870856285095215]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On crée un objet pour train avec flair. Ici on utilise seulement des données de train\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "#On lance le training\n",
    "trainer.train(model_dir,learning_rate=0.1,mini_batch_size=32, max_epochs=10,embeddings_storage_mode='cpu',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<flair.trainers.trainer.ModelTrainer object at 0x7f78b4cdc2d0>\n"
     ]
    }
   ],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4A6DGl1zW3IQ",
    "outputId": "bb8ba455-7d0d-47bf-d348-0aa940b60355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 10:02:56,001 loading file ./best-model.pt\n"
     ]
    }
   ],
   "source": [
    "#On récupère le meilleur modèle, stocké sous ce nom par Flair\n",
    "model = SequenceTagger.load('./best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-883d918e6497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 10:05:21,439 Reading data from flair\n",
      "2020-07-24 10:05:21,441 Train: flair/train.txt\n",
      "2020-07-24 10:05:21,443 Dev: None\n",
      "2020-07-24 10:05:21,444 Test: flair/test.txt\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"./flair\"\n",
    "\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "corpus2: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                                    train_file=None,\n",
    "                                      test_file='test.txt',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, eval_loss = model.evaluate(corpus2.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "- F-score (micro) 0.4444\n",
      "- F-score (macro) 0.2051\n",
      "- Accuracy 0.4444\n",
      "\n",
      "By class:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "I-location_detail     1.0000    0.0000    0.0000         2\n",
      "                O     0.4444    1.0000    0.6154         4\n",
      "         I-arrive     1.0000    0.0000    0.0000         3\n",
      "\n",
      "         accuracy                         0.4444         9\n",
      "        macro avg     0.8148    0.3333    0.2051         9\n",
      "     weighted avg     0.7531    0.4444    0.2735         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-location_detail': {'p': '1.0000', 'r': '0.0000', 'f': '0.0000'},\n",
       " 'O': {'p': '0.4444', 'r': '1.0000', 'f': '0.6154'},\n",
       " 'I-arrive': {'p': '1.0000', 'r': '0.0000', 'f': '0.0000'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_string(res):\n",
    "    res = result.detailed_results\n",
    "    res = res.split('\\n')[:][9:-4]\n",
    "    res =' '.join(str(res).split())\n",
    "    res = res.replace(\"[\\'\",'')\n",
    "    res = res.replace(\"\\']\",'')\n",
    "    res = res.replace(\"', '\",'')\n",
    "    res = res.split()\n",
    "    dico = {}\n",
    "    for i in range(0,len(res),5):\n",
    "        dico[res[i]] = {}\n",
    "        dico[res[i]]['p'] = res[i+1]\n",
    "        dico[res[i]]['r'] = res[i+2]\n",
    "        dico[res[i]]['f'] = res[i+3]\n",
    "    return dico\n",
    "\n",
    "\n",
    "dico= convert_string(result.detailed_results)\n",
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy=sum(Recall[i]*Support[i])/sum(Support[i])\n",
    "\n",
    "acc = (1*2+1*4+0*3)/(4+3+2)\n",
    "print(acc)\n",
    "\n",
    "#Donc possible de calculer l'accuracy globale si on connait les support donc à voir avec SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus2.test[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = corpus2.test[0]\n",
    "sentence =test.to_plain_string()\n",
    "print(sentence)\n",
    "tests = Sentence(sentence)\n",
    "model.predict(tests)\n",
    "print(tests.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMt/t0JxwEffzpT7O9gS5yT",
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

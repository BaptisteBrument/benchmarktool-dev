{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#spaCy imports\n",
    "import spacy\n",
    "from tqdm import tqdm # loading bar\n",
    "from spacy import displacy\n",
    "from spacy.scorer import Scorer\n",
    "import random\n",
    "from spacy.gold import GoldParse\n",
    "\n",
    "\n",
    "#flair imports\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus, ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings,DocumentLSTMEmbeddings, BertEmbeddings, StackedEmbeddings, TokenEmbeddings\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "from typing import List\n",
    "from flair.data import Sentence\n",
    "\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, model_format, model_name, training_data, nb_iter, out_dir):\n",
    "        self.model_name = model_name\n",
    "        self.nb_iter = nb_iter\n",
    "        self.training_data = training_data\n",
    "        self.out_dir = out_dir\n",
    "        self.is_ready = False\n",
    "        self.model_format=model_format.lower()\n",
    "\n",
    "\n",
    "    def convert_format(self):\n",
    "\n",
    "\n",
    "\n",
    "        #spaCy\n",
    "        if self.model_format == \"spacy_format\" :\n",
    "            json_file=self.training_data.get_file()\n",
    "            data=[]\n",
    "            for obj in json_file :\n",
    "                entities = []\n",
    "                for e in obj['entities'] :\n",
    "                    entities.append(tuple(e))\n",
    "                data.append((obj['text'], {'entities' : entities}))\n",
    "            self.training_data=data\n",
    "\n",
    "\n",
    "        #flair\n",
    "        elif self.model_format == \"bio_format\":\n",
    "            file = open(\"./data/format.txt\", \"w\")\n",
    "            pos_beg = 0\n",
    "            pos_end = 1\n",
    "            annot_beg = 0\n",
    "            annot_end = 1\n",
    "            label = None\n",
    "            matches = None\n",
    "            json_file=self.training_data.get_file()\n",
    "            for obj in json_file:\n",
    "                pattern = re.compile(r\"\\w'|\\w+|[^\\w\\s]\")\n",
    "                matches = pattern.finditer(obj['text'])\n",
    "\n",
    "                if not matches:\n",
    "                    print(\"error\")\n",
    "\n",
    "                for m in matches:\n",
    "                    file.write(m.group())\n",
    "                    file.write(\" \")\n",
    "                    pos_beg = m.span()[0]\n",
    "                    pos_end = m.span()[1]\n",
    "\n",
    "                    for e in obj['entities']:\n",
    "                        annot_beg = e[0]\n",
    "                        annot_end = e[1]\n",
    "                        label = e[2]\n",
    "                        #At the beginning of the entity's position\n",
    "                        if pos_beg == annot_beg:\n",
    "                            file.write(\"B-\"+label)\n",
    "                            \n",
    "                        #between the entity's position\n",
    "                        elif pos_beg > annot_beg and pos_end <= annot_end:\n",
    "                            file.write(\"I-\"+label)\n",
    "                        else:\n",
    "                            file.write(\"O\")\n",
    "\n",
    "                    file.write(\"\\n\")\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "            file.close()\n",
    "            self.training_data = \"./data/format.txt\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SpacyModel(Model):\n",
    "    def __init__(self, model_format, model_name, training_data, nb_iter, out_dir,model):\n",
    "        Model.__init__(self,model_format, model_name, training_data, nb_iter, out_dir)\n",
    "        self.visuals = []\n",
    "        if model is not None:\n",
    "            self.nlp = spacy.load(model)\n",
    "            print(\"Loaded model '%s'\" % model)\n",
    "        else:\n",
    "            self.nlp = spacy.blank('fr')\n",
    "            print(\"Created new model\")\n",
    "            \n",
    "        if 'ner' not in self.nlp.pipe_names:\n",
    "            self.ner = self.nlp.create_pipe('ner')\n",
    "            self.nlp.add_pipe(self.ner)\n",
    "        else:\n",
    "            self.ner = self.nlp.get_pipe('ner')\n",
    "        labels = [ label for label in training_data.get_labels()]\n",
    "        for l in labels :\n",
    "            self.ner.add_label(l)\n",
    "        if model is None:\n",
    "            self.optimizer = self.nlp.begin_training()\n",
    "        else:\n",
    "            self.optimizer = self.nlp.entity.create_optimizer()\n",
    "\n",
    "    def get_visuals(self):\n",
    "        return self.visuals \n",
    "            \n",
    "    def train(self):\n",
    "        self.convert_format()\n",
    "        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != 'ner']\n",
    "        with self.nlp.disable_pipes(*other_pipes):\n",
    "            for itn in range(self.nb_iter):\n",
    "                random.shuffle(self.training_data)\n",
    "                losses = {}\n",
    "                for text, annotations in tqdm(self.training_data):\n",
    "                    self.nlp.update([text], [annotations], sgd=self.optimizer, drop=0.35,\n",
    "                        losses=losses)\n",
    "                print(losses)\n",
    "        self.is_ready = True\n",
    "                \n",
    "    def test(self, test_data):\n",
    "        scorer = Scorer()\n",
    "        for sents, ents in test_data:\n",
    "            doc_gold = self.nlp.make_doc(sents)\n",
    "            gold = GoldParse(doc_gold, entities=ents['entities'])\n",
    "            pred_value = self.nlp(sents)\n",
    "            visual = displacy.render(pred_value, style=\"ent\")\n",
    "            visual = visual.replace(\"\\n\\n\",\"\\n\")\n",
    "            self.visuals.append(visual)\n",
    "            scorer.score(pred_value, gold)\n",
    "            print(scorer.scores)\n",
    "        return scorer.scores\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    def save(self):\n",
    "        if self.out_dir is not None:\n",
    "            self.out_dir = Path(self.out_dir)\n",
    "        if not self.out_dir.exists():\n",
    "            self.out_dir.mkdir()\n",
    "        self.nlp.to_disk(self.out_dir)\n",
    "        print(\"Modele saved in :\", self.out_dir)\n",
    "\n",
    "                \n",
    "class FlairModel(Model):\n",
    "    \"\"\"Class to train/test a model using flair\"\"\"\n",
    "    \n",
    "    def __init__(self,model_format, model_name, training_data, nb_iter=10, lr=0.1, batch=32, mode='cpu', out_dir=None):\n",
    "        Model.__init__(self,model_format, model_name, training_data, nb_iter, out_dir)\n",
    "        self.model_name = './'+ model_name\n",
    "        self.learning_rate=lr\n",
    "        self.batch_size=batch\n",
    "        self.mode=mode\n",
    "        self.training_data = training_data\n",
    "        \n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.convert_format()\n",
    "       \n",
    "        corpus: Corpus = ColumnCorpus(\".\", {0: 'text', 1: 'ner'},\n",
    "                                      train_file=self.training_data\n",
    "                                      )\n",
    "        tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
    "        embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "            WordEmbeddings('fr'),\n",
    "            FlairEmbeddings('fr-forward'),\n",
    "            FlairEmbeddings('fr-backward'),\n",
    "        ]\n",
    "\n",
    "        embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "        tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                                embeddings=embeddings,\n",
    "                                                tag_dictionary=tag_dictionary,\n",
    "                                                tag_type='ner',\n",
    "                                                use_crf=True)\n",
    "        self.trainer = ModelTrainer(tagger, corpus)\n",
    "        self.trainer.train(self.model_name,learning_rate=self.learning_rate,mini_batch_size=self.batch_size, max_epochs=self.nb_iter,embeddings_storage_mode=self.mode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def test(self, test_data):\n",
    "        model = SequenceTagger.load(self.model_name+'/best-model.pt')\n",
    "\n",
    "        corpus: Corpus = ColumnCorpus(\".\", {0: 'text', 1: 'ner'},\n",
    "                                        train_file=None,\n",
    "                                        test_file=test_data\n",
    "                                      )\n",
    "        result, eval_loss = model.evaluate(corpus.test)\n",
    "        # permet de retourner un dictionnaire de la mÃªme forme que celui fourni pas spaCy\n",
    "        res = result.detailed_results\n",
    "        res = res.split('\\n')[:][9:-4]\n",
    "        res =' '.join(str(res).split())\n",
    "        res = res.replace(\"[\\'\",'')\n",
    "        res = res.replace(\"\\']\",'')\n",
    "        res = res.replace(\"', '\",'')\n",
    "        res = res.split()\n",
    "        scores = {}\n",
    "        for i in range(0,len(res),5):\n",
    "            scores[res[i]] = {}\n",
    "            scores[res[i]]['p'] = res[i+1]\n",
    "            scores[res[i]]['r'] = res[i+2]\n",
    "            scores[res[i]]['f'] = res[i+3]\n",
    "        return scores\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataset : Parent class - checks and stores the data structure of an annotated JSON file.\n",
    "    TrainData : Child class - specific to training dataset: allows to store metadata.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, title):\n",
    "        self.title = title\n",
    "        self.file = []\n",
    "    \n",
    "    def get_title(self):\n",
    "        return self.title\n",
    "    \n",
    "    def get_file(self):\n",
    "        return self.file\n",
    "\n",
    "    def filter_json(self, json_file):\n",
    "        \"\"\"keeps only the text elements and entities of the JSON file\"\"\"\n",
    "        file = []\n",
    "        for o in json_file:\n",
    "            try:\n",
    "                text = o['text']\n",
    "                try:\n",
    "                    entities = o['entities']\n",
    "                    if not text or not entities : \n",
    "                        return\n",
    "\n",
    "                except:\n",
    "                    return\n",
    "            except:\n",
    "                return\n",
    "            obj = {'text' : text, 'entities' : entities}\n",
    "            file.append(obj)\n",
    "        self.file = file\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def is_correct(self):\n",
    "        \"\"\"checks if the content of the file is correct\"\"\"\n",
    "\n",
    "        r_str = \"((\\\"[^\\\"]+\\\")|(\\'[^\\']+\\'))\"\n",
    "        r_entity = \"\\[\\d+,\\s*\\d+,\\s*\" + r_str + \"\\]\"\n",
    "        for obj in self.file:\n",
    "            entity = obj['entities']\n",
    "            if not entity :\n",
    "                return False\n",
    "            for e in entity:\n",
    "                if not re.fullmatch(r_entity, str(e)) or e[0] >= e[1]:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "\n",
    "#### TrainData\n",
    "\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self, title):\n",
    "        Dataset.__init__(self, title)\n",
    "        self.hash = \"\"\n",
    "        self.nb_entities = 0\n",
    "        self.labels = []\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"print(obj)\"\"\"\n",
    "        return 'the dataset \"'+ self.title +'\" has '+ str(self.nb_entities) +' entities.'\n",
    "    \n",
    "    def get_nb_entities(self):\n",
    "        return self.nb_entities\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def get_hash(self):\n",
    "        return self.hash\n",
    "    \n",
    "    def metadata(self):\n",
    "        \"\"\"completes the object properties to create metadata\"\"\"       \n",
    "        dic = {}\n",
    "        nb_entities = 0\n",
    "        for obj in self.file:\n",
    "            self.nb_entities += len(obj['entities'])\n",
    "            for e in obj['entities']:\n",
    "                dic.setdefault(e[2], 0)\n",
    "                dic[e[2]] += 1\n",
    "        self.labels = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1],reverse = True)}        \n",
    "            \n",
    "        #MD5 hash - encoded data in hexadecimal format.\n",
    "        self.hash = hashlib.md5(str(self.file).encode()).hexdigest()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/cheval_annotated.json\", \"r\") as file :\n",
    "    content = file.read()\n",
    "    content = json.loads(content)\n",
    "train = TrainData(\"data\")\n",
    "train.filter_json(content)\n",
    "train.is_correct()\n",
    "train.metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_model = FlairModel(model_format = \"bio_format\", model_name =\"test\", training_data = train,nb_iter=1, lr=0.1, batch=32, mode='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-12 15:03:41,309 Reading data from .\n",
      "2020-08-12 15:03:41,313 Train: data/format.txt\n",
      "2020-08-12 15:03:41,315 Dev: None\n",
      "2020-08-12 15:03:41,316 Test: None\n",
      "2020-08-12 15:03:50,202 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:50,204 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('fr')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (encoder): Embedding(275, 100)\n",
      "        (rnn): LSTM(100, 1024)\n",
      "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (encoder): Embedding(275, 100)\n",
      "        (rnn): LSTM(100, 1024)\n",
      "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2348, out_features=2348, bias=True)\n",
      "  (rnn): LSTM(2348, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-08-12 15:03:50,205 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:50,206 Corpus: \"Corpus: 40 train + 4 dev + 5 test sentences\"\n",
      "2020-08-12 15:03:50,207 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:50,208 Parameters:\n",
      "2020-08-12 15:03:50,209  - learning_rate: \"0.1\"\n",
      "2020-08-12 15:03:50,213  - mini_batch_size: \"32\"\n",
      "2020-08-12 15:03:50,215  - patience: \"3\"\n",
      "2020-08-12 15:03:50,225  - anneal_factor: \"0.5\"\n",
      "2020-08-12 15:03:50,226  - max_epochs: \"1\"\n",
      "2020-08-12 15:03:50,227  - shuffle: \"True\"\n",
      "2020-08-12 15:03:50,228  - train_with_dev: \"False\"\n",
      "2020-08-12 15:03:50,229  - batch_growth_annealing: \"False\"\n",
      "2020-08-12 15:03:50,233 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:50,234 Model training base path: \"test\"\n",
      "2020-08-12 15:03:50,235 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:50,236 Device: cpu\n",
      "2020-08-12 15:03:50,237 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:50,242 Embeddings storage mode: cpu\n",
      "2020-08-12 15:03:50,246 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:52,300 epoch 1 - iter 1/2 - loss 16.14271736 - samples/sec: 15.60\n",
      "2020-08-12 15:03:54,795 epoch 1 - iter 2/2 - loss 11.57050347 - samples/sec: 43.42\n",
      "2020-08-12 15:03:56,485 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:03:56,488 EPOCH 1 done: loss 11.5705 - lr 0.1000000\n",
      "2020-08-12 15:03:57,180 DEV : loss 4.765364646911621 - score 0.0\n",
      "2020-08-12 15:03:57,182 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-08-12 15:05:27,350 ----------------------------------------------------------------------------------------------------\n",
      "2020-08-12 15:05:27,352 Testing using best model ...\n",
      "2020-08-12 15:05:27,354 loading file test/best-model.pt\n",
      "2020-08-12 15:06:34,739 0.0000\t0.0000\t0.0000\n",
      "2020-08-12 15:06:34,741 \n",
      "Results:\n",
      "- F1-score (micro) 0.0000\n",
      "- F1-score (macro) 0.0000\n",
      "\n",
      "By class:\n",
      "ANIMAL     tp: 0 - fp: 0 - fn: 5 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
      "2020-08-12 15:06:34,742 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "flair_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-12 15:08:37,413 loading file ./test/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "test_text = [(\"On dit qu\\'un cheval est calme\",{\n",
    "            'entities': [(13, 19, 'ANIMAL')]\n",
    "            }),\n",
    "            (\"Un cheval endormi n\\'est pas nÃ©cessairement un cheval calme\",{\n",
    "             'entities': [(3, 9, 'ANIMAL'),(46,51, 'ANIMAL')]   \n",
    "            }),\n",
    "            (\"souhaitez vous apprendre Ã  monter Ã  cheval?\",{\n",
    "             'entities' : [(36,41,'ANIMAL')]\n",
    "            }),\n",
    "            (\"Pour moi les chevaux sont les meilleurs animaux aprÃ¨s les chats\",{\n",
    "             'entities' : [(13,20,'ANIMAL'),(58,63, 'ANIMAL')]\n",
    "            })\n",
    "           ]\n",
    "\n",
    "score=flair_model.test(test_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
